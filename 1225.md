### 12/24





### 12/25

讨论爬取网址，尝试爬取不同的网址，复现老师所教授的代码，发现由于反爬的限制，有些网址无法爬取数据。如何查看网址是否设置反爬呢？（实际上，我们现在所学的爬取数据是爬取html的标签内容，而目前大部分主流网址则用jason等脚本语言生成网址，所以无法通过网页来爬取）

使用F12中的网络部分（录制网络响应）

![image-20231226144156435](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231226144156435.png)

点击第一个网页，并使用ctrl+f使用搜索功能![image-20231226144424942](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231226144424942.png)

例如搜索“ 迈腾 2023款 200万辆纪念版 330TSI DSG豪华型”，可以看到网页能找到对应内容



对于无法爬取的网址，如淘宝：![image-20231226144900121](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231226144900121.png)

搜索“ROG玩家国度”可以看到，无法在serch中寻找到对应内容，说明该网址无法通过html来爬取网址

### 12-26

爬取网页内容时，发现按照元素页面的标签来爬取数据，虽然全都按照内容来写的代码，却始终无法获取到内容

```python
 divName = response.xpath('//div[@class="info--wrap"]')
 name = Title.xpath(
     'div[@class="info--desc"]/a/h2/span/text()').extract()
```





!![image-20231226152109561](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231226152109561.png)(C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231226151543052.png)

最后在网络响应界面发现，a的标签是‘’info--wrap‘’的子级，而在元素中，a标签是‘’info--desc‘’的同级，所以修改代码如下，则可以成功爬取数据

```python
 name = Title.xpath(
                'a/div[@class="info--desc"]/h2/span/text()').extract()
```



![image-20231226151510595](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231226151510595.png)

其中，通过老师所上传的debug--main文件，可用来对项目进行debug

![image-20231228113108587](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228113108587.png)

将图中划线部分更改为自己的spider文件，并对需要debug处打断点，运行main-debug，便可执行debug操作，如：

![image-20231228113347707](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228113347707.png)

运行divName15行代码后，可以得知数据成功地传回到了divName，其中有50个数据，由此可以判断是否爬取到数据。

![image-20231228113619333](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228113619333.png)

如图是成功爬取后的terminal界面。

##### 无法爬取数据的原因总结如下：

当出现crwaled（403）的情况是，可能是setting中的Item_Pipeline未设置，需要在注释的第53行设置成以下界面（画横线的是自己的项目名称）：

![image-20231228114005770](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228114005770.png)

当debug界面出现有robot的字样是，则需要将![image-20231228114256457](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228114256457.png)由True改成False

当出现Redirecting(302)的情况时，可能是由于爬取次数太频繁被网址所检测，那么需要换一个网络重新进行爬取数据

![](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228114233375.png)

进入其中的网址如下所示![image-20231228114547514](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228114547514.png)

### 12/27

成功爬取页面后，使用url对界面进行拼接实现翻页效果，核心代码如下：

```python
def parse(self, response):
        divName = response.xpath('//div[@class="info--wrap"]')
	while(cont<2):
            time.sleep(2)
        #翻页，深度爬取数据
            nextPage = response.xpath('//div[@class="pager"]/a[12]/@href')
        #判断nextPage存在就拼接url进行请求
            if nextPage:
            #拼接url
                url = nextPage[0].extract()
            #请求url使用self.parse解析
                cont+=1
                yield scrapy.Request(url, self.parse)
```



如图所示：

<img src="C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228210147235.png" alt="image-20231228210147235" style="zoom:50%;" />

当出现crawled 2 pages，可以知道成功实现了翻页功能。但同样地，使用翻页功能会爬取大量数据，容易被网站检测到，导致出现验证界面，所以我们最后决定不使用翻页功能，避免个人ip被网站封禁。

使用数据库功能将数据保存到数据库中，由于提取的数据存在无效字段，所以需要对字段进行数据清洗，代码如下：

```python
sql = "insert into `deliveryPerson3`(`brand`,`name3`,`uptime`,`distance`) values(%s,%s,%s,%s)"
            brand = item['brand'][0].replace('\n', '').replace(" ", "")
            name3 = item['name3'][0].replace('\n', '').replace(" ", "")
            uptime = item['uptime'][0].replace('\n', '').replace(" ", "")
            distance = item['uptime'][-1].replace('\n', '').replace(" ", "")
            params = (brand, name3, uptime, distance)
            affectedRows = dbExecuteSQL(sql, params)
```

提取后的数据如下：

![image-20231228210745713](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228210745713.png)



### 12/28

使用Pyechart进行数据展示，发现实例代码中的数据需要自己通过sql语句进行修改，核心代码如下：

```python
```sql = 'select `brand`, `distance` from deliveryperson3 limit %s, %s'

params = (0, 50)

result = dbQueryAllSQL(sql, params)

\#print(list(result))

\# 数据

brand = []

distance = []



for row in result:

  brand.append(row[0])

  \# gz = row[1].split(" ")

  distance.append(row[1])
```

```python
sql = 'select `brand`, `distance` from deliveryperson3 limit %s, %s'
#  使用sql语句将数据存入到sql中
params = (0, 50)
result = dbQueryAllSQL(sql, params)
#传入数据到result，通过调用dbQueryAllSQL以游标的形式将数据库中的数据保存到ressult中
brand = []
distance = []
#创建列表，以保存数据
for row in result:
brand.append(row[0])
#将result列表中的第一个元素传入到brand中，再使用append连接多个数据
distance.append(row[1])
distance = [brand_item.replace('万公里', '') for brand_item in distance]
#使用replace将字段‘万公里’去除
distance = list(map(int, distance))
#使用map函数将list中的元素转化为int型

```



可视化后的图标如下所示：

![image-20231228224046152](C:\Users\jax\AppData\Roaming\Typora\typora-user-images\image-20231228224046152.png)
